---
---

------

@ARTICLE{SemEval,
  author={Andre Lamurias, Diana Sousa, Sofia Pereira, Luka Clarke, and Francisco M. Couto},
  journal={Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)}, 
  title="{ULISBOA at SemEval-2017 Task 12: Extraction and classification of temporal expressions and events}",
  year={2017},
  volume={},
  number={},
  pages={1019-1023},
  doi={10.18653/v1/S17-2179},
  selected={true},
  Slides = "",
  preview = "",
  abbr = "SemEval",
  abstract = {This paper presents our approach to participate in the SemEval 2017 Task 12: Clinical TempEval challenge, specifically in the event and time expressions span and attribute identification subtasks (ES, EA, TS, TA). Our approach consisted in training Conditional Random Fields (CRF) classifiers using the provided annotations, and in creating manually curated rules to classify the attributes of each event and time expression. We used a set of common features for the event and time CRF classifiers, and a set of features specific to each type of entity, based on domain knowledge. Training only on the source domain data, our best F-scores were 0.683 and 0.485 for event and time span identification subtasks. When adding target domain annotations to the training data, the best F-scores obtained were 0.729 and 0.554, for the same subtasks. We obtained the second highest F-score of the challenge on the event polarity subtask (0.708). The source code of our system, Clinical Timeline Annotation (CiTA), is available at https://github.com/lasigeBioTM/CiTA.},
  url = "https://aclanthology.org/S17-2179/",
  pdf = "https://aclanthology.org/S17-2179.pdf"
}

@ARTICLE{BO-LSTM,
  author={Andre Lamurias, Diana Sousa, Luka A. Clarke and Francisco M. Couto},
  journal={BMC Bioinformatics}, 
  title="{BO-LSTM: classifying relations via long short-term memory networks along biomedical ontologies}",
  year={2019},
  volume={20},
  number={10},
  pages={},
  doi={10.1186/s12859-018-2584-5},
  selected={true},
  Slides = "",
  preview = "",
  abbr = "BMC",
  abstract = {Recent studies have proposed deep learning techniques, namely recurrent neural networks, to improve biomedical text mining tasks. However, these techniques rarely take advantage of existing domain-specific resources, such as ontologies. In Life and Health Sciences there is a vast and valuable set of such resources publicly available, which are continuously being updated. Biomedical ontologies are nowadays a mainstream approach to formalize existing knowledge about entities, such as genes, chemicals, phenotypes, and disorders. These resources contain supplementary information that may not be yet encoded in training data, particularly in domains with limited labeled data. We propose a new model to detect and classify relations in text, BO-LSTM, that takes advantage of domain-specific ontologies, by representing each entity as the sequence of its ancestors in the ontology. We implemented BO-LSTM as a recurrent neural network with long short-term memory units and using open biomedical ontologies, specifically Chemical Entities of Biological Interest (ChEBI), Human Phenotype, and Gene Ontology. We assessed the performance of BO-LSTM with drug-drug interactions mentioned in a publicly available corpus from an international challenge, composed of 792 drug descriptions and 233 scientific abstracts. By using the domain-specific ontology in addition to word embeddings and WordNet, BO-LSTM improved the F1-score of both the detection and classification of drug-drug interactions, particularly in a document set with a limited number of annotations. We adapted an existing DDI extraction model with our ontology-based method, obtaining a higher F1 score than the original model. Furthermore, we developed and made available a corpus of 228 abstracts annotated with relations between genes and phenotypes, and demonstrated how BO-LSTM can be applied to other types of relations. Our findings demonstrate that besides the high performance of current deep learning techniques, domain-specific ontologies can still be useful to mitigate the lack of labeled data.},
  url = "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2584-5",
  pdf = "https://bmcbioinformatics.biomedcentral.com/counter/pdf/10.1186/s12859-018-2584-5.pdf"
}

@ARTICLE{PGR,
  author = {Diana Sousa, Andre Lamurias, Francisco M. Couto},
  journal = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, 
  title = "{A Silver Standard Corpus of Human Phenotype-Gene Relations}",
  year = {2019},
  volume = {},
  number = {},
  pages = {1487-1492},
  doi = {10.18653/v1/N19-1152},
  selected = {true},
  Slides = "",
  preview = "",
  abbr = "NAACL",
  abstract = {Human phenotype-gene relations are fundamental to fully understand the origin of some phenotypic abnormalities and their associated diseases. Biomedical literature is the most comprehensive source of these relations, however, we need Relation Extraction tools to automatically recognize them. Most of these tools require an annotated corpus and to the best of our knowledge, there is no corpus available annotated with human phenotype-gene relations. This paper presents the Phenotype-Gene Relations (PGR) corpus, a silver standard corpus of human phenotype and gene annotations and their relations. The corpus consists of 1712 abstracts, 5676 human phenotype annotations, 13835 gene annotations, and 4283 relations. We generated this corpus using Named-Entity Recognition tools, whose results were partially evaluated by eight curators, obtaining a precision of 87.01%. By using the corpus we were able to obtain promising results with two state-of-the-art deep learning tools, namely 78.05% of precision. The PGR corpus was made publicly available to the research community.},
  url = "https://aclanthology.org/N19-1152/",
  pdf = "https://aclanthology.org/N19-1152.pdf"
}

@ARTICLE{BiOnt,
  author = {Diana Sousa and Francisco M. Couto },
  journal = {Advances in Information Retrieval: 42nd European Conference on IR Research}, 
  title = "{BiOnt: Deep Learning Using Multiple Biomedical Ontologies for Relation Extraction}",
  year = {2020},
  volume = {},
  number = {},
  pages = {},
  doi = {10.1007/978-3-030-45442-5_46},
  selected = {true},
  Slides = "",
  preview = "",
  abbr = "ECIR",
  abstract = {Successful biomedical relation extraction can provide evidence to researchers and clinicians about possible unknown associations between biomedical entities, advancing the current knowledge we have about those entities and their inherent mechanisms. Most biomedical relation extraction systems do not resort to external sources of knowledge, such as domain-specific ontologies. However, using deep learning methods, along with biomedical ontologies, has been recently shown to effectively advance the biomedical relation extraction field. To perform relation extraction, our deep learning system, BiOnt, employs four types of biomedical ontologies, namely, the Gene Ontology, the Human Phenotype Ontology, the Human Disease Ontology, and the Chemical Entities of Biological Interest, regarding gene-products, phenotypes, diseases, and chemical compounds, respectively. We tested our system with three data sets that represent three different types of relations of biomedical entities. BiOnt achieved, in F-score, an improvement of 4.93 percentage points for drug-drug interactions (DDI corpus), 4.99 percentage points for phenotype-gene relations (PGR corpus), and 2.21 percentage points for chemical-induced disease relations (BC5CDR corpus), relatively to the state-of-the-art. The code supporting this system is available at https://github.com/lasigeBioTM/BiOnt.},
  url = "https://link.springer.com/chapter/10.1007/978-3-030-45442-5_46",
  pdf = "https://link.springer.com/content/pdf/10.1007/978-3-030-45442-5_46.pdf?pdf=inline%20link"
}


@ARTICLE{Geonm,
  author = {Diana Sousa, Andre Lamurias, Francisco M. Couto},
  journal = {Genomics & Informatics}, 
  title = "{Improving accessibility and distinction between negative results in biomedical relation extraction}",
  year = {2020},
  volume = {},
  number = {},
  pages = {},
  doi = {10.5808/GI.2020.18.2.e20},
  selected = {true},
  Slides = "",
  preview = "",
  abbr = "",
  abstract = {Accessible negative results are relevant for researchers and clinicians not only to limit their search space but also to prevent the costly re-exploration of research hypotheses. However, most biomedical relation extraction datasets do not seek to distinguish between a false and a negative relation among two biomedical entities. Furthermore, datasets created using distant supervision techniques also have some false negative relations that constitute undocumented/unknown relations (missing from a knowledge base). We propose to improve the distinction between these concepts, by revising a subset of the relations marked as false on the phenotype-gene relations corpus and give the first steps to automatically distinguish between the false (F), negative (N), and unknown (U) results. Our work resulted in a sample of 127 manually annotated FNU relations and a weighted-F1 of 0.5609 for their automatic distinction. This work was developed during the 6th Biomedical Linked Annotation Hackathon (BLAH6).},
  url = "https://genominfo.org/journal/view.php?doi=10.5808/GI.2020.18.2.e20",
  pdf = "https://genominfo.org/upload/pdf/gi-2020-18-2-e20.pdf"
}


# Thesis
@ARTICLE{Magnet,
author={Ankit Pal and Muru Selvakumar and Malaikannan Sankarasubbu},
journal={Proceedings of the 12th International Conference on Agents and Artificial Intelligence}, 
title="{MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network}",
year={2020},
volume={},
number={},
pages={1-1},
doi={10.5220/0008940304940505},
selected={true},
Slides = "https://github.com/monk1337/ResearchSlides/blob/main/Magnet_paper/Presentation_slides.pdf",
preview="magnet.gif",
abbr = "ICAART",
abstract = {In Multi-Label Text Classification (MLTC), one sample can belong to more than one class. It is observed that most MLTC tasks, there are dependencies or correlations among labels. Existing methods tend to ignore the relationship among labels. In this paper, a graph attention network-based model is proposed to capture the attentive dependency structure among the labels. The graph attention network uses a feature matrix and a correlation matrix to capture and explore the crucial dependencies between the labels and generate classifiers for the task. The generated classifiers are applied to sentence feature vectors obtained from the text feature extraction network (BiLSTM) to enable end-to-end training. Attention allows the system to assign different weights to neighbor nodes per label, thus allowing it to learn the dependencies among labels implicitly. The results of the proposed model are validated on five real-world MLTC datasets. The proposed model achieves similar or better performance compared to the previous state-of-the-art models.},
url = "https://doi.org/10.5220%2F0008940304940505",
pdf = "https://arxiv.org/pdf/2003.11644.pdf"
}

@ARTICLE{Cough,
author={Ankit Pal and Malaikannan Sankarasubbu},
journal={Proceedings of the 36th Annual ACM Symposium on Applied Computing}, 
title="{Pay Attention to the cough: Early Diagnosis of COVID-19 using Interpretable Symptoms Embeddings with Cough Sound Signal Processing}",
year={2021},
volume={},
number={},
pages={1-1},
doi={10.1145/3412841.3441943},
website = "https://coughresearch.github.io/",
selected={true},
Slides = "https://github.com/monk1337/ResearchSlides/blob/main/Cough_paper/presentation_slides.pdf",
code = "https://github.com/coughresearch/Cough-signal-processing",
preview="cough.png",
abbr = "ACM",
abstract = {COVID-19 (coronavirus disease 2019) pandemic caused by SARS-CoV-2 has led to a treacherous and devastating catastrophe for humanity. At the time of writing, no specific antivirus drugs or vaccines are recommended to control infection transmission and spread. The current diagnosis of COVID-19 is done by Reverse-Transcription Polymer Chain Reaction (RT-PCR) testing. However, this method is expensive, time-consuming, and not easily available in straitened regions. An interpretable and COVID-19 diagnosis AI framework is devised and developed based on the cough sounds features and symptoms metadata to overcome these limitations. The proposed framework's performance was evaluated using a medical dataset containing Symptoms and Demographic data of 30000 audio segments, 328 cough sounds from 150 patients with four cough classes ( COVID-19, Asthma, Bronchitis, and Healthy). Experiments' results show that the model captures the better and robust feature embedding to distinguish between COVID-19 patient coughs and several types of non-COVID-19 coughs with higher specificity and accuracy of 95.04 ± 0.18\% and 96.83± 0.18\% respectively, all the while maintaining interpretability.},
url = "https://dl.acm.org/doi/10.1145/3412841.3441943",
pdf = "https://dl.acm.org/doi/pdf/10.1145/3412841.3441943"
}

@ARTICLE{Clift,
author={Ankit Pal},
journal={NeurIPS-2022: Robustness in Sequence Modeling}, 
title="{CLIFT: Analysing Natural Distribution Shift on Question Answering Models in Clinical Domain}",
year={2022},
volume={},
number={},
pages={1-1},
selected={true},
Poster = "https://nips.cc/media/PosterPDFs/NeurIPS\%202022/58229.png?t=1668359616.0178533",
abbr = "NeurIPS",
abstract = {This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical domain Question Answering task. The testbed includes 7.5k high-quality questionanswering samples to provide a diverse and reliable benchmark. We performed a comprehensive experimental study and evaluated several QA deep-learning models under the proposed testbed. Despite impressive results on the original test set, the performance degrades when applied to new test sets, which shows the distribution shift. Our findings emphasize the need for and the potential for increasing the robustness of clinical domain models under distributional shifts. The testbed offers one way to track progress in that direction. It also highlights the necessity of adopting evaluation metrics that consider robustness to natural distribution shifts. We plan to expand the corpus by adding more samples and model results. The full paper and the updated benchmark are available at openlifescience-ai.github.io/clift},
url = "https://nips.cc/virtual/2022/58229",
pdf = "https://openreview.net/pdf?id=9PQFROOfqm"
}

@ARTICLE{MedMCQA,
author={Ankit Pal and Logesh Kumar Umapathi and Malaikannan Sankarasubbu},
journal={Proceedings of Machine Learning Research(PMLR)},
title="{MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering}",
year={2022},
volume={},
number={},
pages={1-1},
selected={true},
Slides = "https://github.com/monk1337/ResearchSlides/blob/main/MedMCQA_paper/presentation_slides.pdf",
code = "https://github.com/medmcqa/medmcqa",
Benchmark = "https://medmcqa.github.io/",
preview="medmcqa.png",
abstract = 	 {This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS &amp; NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects &amp; topics. A detailed explanation of the solution, along with the above information, is provided in this study.},
url = "https://proceedings.mlr.press/v174/pal22a.html",
pdf = "https://proceedings.mlr.press/v174/pal22a/pal22a.pdf"
}

@ARTICLE{FedLearn,
author={Madhura Joshi* and Ankit Pal* and Malaikannan Sankarasubbu},
journal={ACM Transactions on Computing for Healthcare},
title="{Federated learning for healthcare domain - pipeline, applications and challenges}",
year={2022},
volume={},
number={},
pages={1-1},
selected={true},
Slides = "https://github.com/monk1337/ResearchSlides/blob/main/Federated_learning_paper/presentation_slides.pdf",
preview="fedlearn.png",
abstract = 	 {Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This survey examines previous research and studies on federated learning in the healthcare sector across a range of use cases and applications. Our survey shows what challenges, methods, and applications a practitioner should be aware of in the topic of federated learning. This paper aims to lay out existing research and list the possibilities of federated learning for healthcare industries.},
url = "https://dl.acm.org/doi/10.1145/3533708",
pdf = "https://dl.acm.org/doi/pdf/10.1145/3533708"
}

@ARTICLE{DeepParliament,
author={Ankit Pal},
journal={Empirical Methods in Natural Language Processing(UM-IoS)},
title="{DeepParliament: A Legal domain Benchmark & Dataset for Parliament Bills Prediction}",
year={2022},
volume={},
number={},
pages={1-1},
selected={true},
abbr = "EMNLP",
code = "https://github.com/monk1337/DeepParliament/tree/main",
abstract = 	 {This paper introduces DeepParliament, a legal domain Benchmark Dataset that gathers bill documents and metadata and performs various bill status classification tasks. The proposed dataset text covers a broad range of bills from 1986 to the present and contains richer information on parliament bill content. Data collection, detailed statistics and analyses are provided in the paper. Moreover, we experimented with different types of models ranging from RNN to pretrained and reported the results. We are proposing two new benchmarks: Binary and Multi-Class Bill Status classification. Models developed for bill documents and relevant supportive tasks may assist Members of Parliament (MPs), presidents, and other legal practitioners. It will help review or prioritise bills, thus speeding up the billing process, improving the quality of decisions and reducing the time consumption in both houses. Considering that the foundation of the country”s democracy is Parliament and state legislatures, we anticipate that our research will be an essential addition to the Legal NLP community. This work will be the first to present a Parliament bill prediction task. In order to improve the accessibility of legal AI resources and promote reproducibility, we have made our code and dataset publicly accessible at github.com/monk1337/DeepParliament.},
url = "https://aclanthology.org/2022.umios-1.8/",
pdf = "https://aclanthology.org/2022.umios-1.8.pdf"
}

@ARTICLE{MedHALT,
author={Ankit Pal and Logesh Kumar Umapathi and Malaikannan Sankarasubbu},
journal={Empirical Methods in Natural Language Processing(Conll)},
title="{Med-HALT: Medical Domain Hallucination Test for Large Language Models}",
year={2023},
volume={},
number={},
pages={1-1},
selected={true},
Slides = "",
Benchmark = "http://medhalt.github.io/",
code = "https://github.com/medhalt/medhalt",
preview="medhalt.png",
abstract = {This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities. Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting transparency and reproducibility. Through this work, we aim to contribute to the development of safer and more reliable language models in healthcare. Our benchmark can be found at medhalt.github.io},
url = "https://arxiv.org/abs/2307.15343",
pdf = "https://arxiv.org/pdf/2307.15343.pdf"
}
